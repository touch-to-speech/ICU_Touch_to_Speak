ICU Touch To Speak
==================

ICU Touch to Speak is an open source switch-operated, web-based application designed to be used by nonverbal patients in an Intensive Care Unit (ICU) for communicating with nurses, medical staff and family. It has been developed at the University of Otago, Dunedin, New Zealand.   

## The vision behind ICU Touch To Speak
Worldwide, millions of people are admitted to an ICU each year. One of the most difficult things an ICU patient has to cope with is their inability to communicate. Our vision is to create a device that will serve to reduce the trauma this causes by providing an alternative way to communicate. 

ICU patients who are left temporarily voiceless often suffer psychological distress, frustration and even panic.  They have reported feeling powerless, and incomplete, like an integral part of their body was cut off. This emotional distress often contributes to a  post-traumatic stress disorder during recovery and the psychological effects can be long-lasting. Being rendered voiceless is particularly difficult for those who are are being mechanically ventilated; this occurs either through a plastic tube inserted in their throat via their mouth or via a tube in their neck (referred to as a tracheostomy). Many of these patients have limited fine motor skills, either because they are injured or because their hands are temporarily restrained in the ICU by attachments to monitors and drips. This leaves them unable to gesture or write.

ICU Touch To Speak aims to develop a device that meets the basic communication needs (functional, emotional and social) of nonverbal ICU patients with limited fine motor skills.

## ICU Touch To Speak's point of difference 
Compared to the alternatives currently available, our switch-based computer system, encompassing hardware, software and human-computer interface, offers the following advantages:
* It can be configured for one or two switches, or any keystroke event-based human interface (HID).
* It is be able to run in any common web-browser.
* It allows the nonverbal patient to initiate communication, even when they have limited mobility.
* Its interface could be adapted to a specific local context (rather than being a generic app). 

## Features
The system is:
* self-contained in that all setup is done within the browser;
* designed to be modularised (written in JavaScript);
* styled in CSS, using CSS grid throughout, for placement of button and such.

## The point we are at
This repository contains code for a working prototype, including a basic interface. In 2019, a group of SHIFT students at the University of Otago — students studying for a graduate diploma in Information and Communication Technology — developed this working prototype and made it available to the open source community. 

The prototype, along with a additional list of requirements (in the Appendix of the strategic case, attached to this page), constitute the requirements for the development of this device. This list of requirements has largely been derived from the literature (cited in the strategic case bibliography) and needs to be tested with ICU staff and patients. 
 
There's a raft of possibilities for expanding the system's functionality, including:

1.	integration with other third-party apps, to allow users to gain control over things such as entertainment; 
2.	inclusion of a glossary feature that allows patients to find information about their condition;
3.	for patients that are disoriented or confused, inclusion of reminders about such matters as the patient’s profile (name, age), hospital they are in, their condition, the nature of incident that resulted in their admission, and visitors;
4.	inclusion of a feature reminding the patient about what the nurse told him/her that day;
5.	addition of a mechanism to store a patient’s most frequently used phrases (customisable to the patient);
6.	inclusion of features that allow family to leave a message on the device and to record a video that is then available for the patient to watch wherever they want.

## Interested in working on this project? 
Here's what to do:
* read the strategic case, including the requirements
* build a physical system consisting of two switches connected to your device(bluetooth, USB, etcetera)
* download the code [which will be added to this site in September 2019]
* conduct a heuristic evaluation of the interface, user test and improve it
* check the specification of the other (non-usability) requirements with potential users such as ICU staff
* take it to the next level!

